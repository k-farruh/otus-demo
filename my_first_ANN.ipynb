{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my-first-ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFBhl3fEX6CK7jmQr7cCk2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-farruh/otus-demo/blob/main/my_first_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeHS0SXr4N-K"
      },
      "source": [
        "## Сверточные Нейронные Сети с Нуля"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-g7Ld4I0oar"
      },
      "source": [
        "Этот блокнот содержит последовательность действие для обучения глубокому обучению, Apache MXNet и Gluon интерфейс. Цель - использовать сильные стороны Jupyter Notebook для представления прозы, графики, уравнений и кода в одном месте. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldIOrXE90_fO",
        "outputId": "97653423-cf09-4921-c9e9-69d1ef2c130f"
      },
      "source": [
        "# Устанавливаем mxnet библиотеку\n",
        "!pip install mxnet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/20/76af36cad6754a15f39d3bff19e09921dec72b85261e455d4edc50ebffa8/mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.7.0.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ec1DcQo1Dq8"
      },
      "source": [
        "# Импортируем нужные библиотеки\n",
        "from __future__ import print_function\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "from mxnet import nd, autograd, gluon\n",
        "# В зависимости можете выбрать CPU или GPU\n",
        "ctx = mx.cpu()\n",
        "# ctx = mx.gpu()\n",
        "mx.random.seed(1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrNJ9qUL2_qX"
      },
      "source": [
        "Заружаем MNIST датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkpifRl_1w1H",
        "outputId": "bf7935c8-f098-411f-a5c9-fbd14eac0a33"
      },
      "source": [
        "batch_size = 64\n",
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "def transform(data, label):\n",
        "    return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
        "train_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=True, transform=transform),\n",
        "                                      batch_size, shuffle=True)\n",
        "test_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=False, transform=transform),\n",
        "                                     batch_size, shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/datasets/mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-images-idx3-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDDKvhZg4EfD"
      },
      "source": [
        "Сверточные нейронные сети включают сверточные слои. Эти уровни связывают каждый из своих узлов с небольшим окном, называемым  receptive field (восприимчивым полем), на предыдущем уровне, вместо того, чтобы подключаться к полному слою. Это позволяет нам сначала изучить локальные особенности с помощью преобразований. Затем собираем всю локальную информацию, чтобы предсказать общие качества изображения.\n",
        "\n",
        "Вкрадце, есть две концепции, которые вам нужно изучить. Сначала мы познакомимся со сверточными слоями, потом расмотрим их с объединяющими слоями."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKhA9Mh5XDn"
      },
      "source": [
        "Каждый узел в сверточном слое связан с трехмерным блоком (высота x ширина x канал) во входном тензоре. Более того, сам сверточный слой имеет несколько выходных каналов. Таким образом, слой параметризуется 4-мерным весовым тензором, обычно называемым сверточным ядром.\n",
        "\n",
        "Выходной тензор создается путем скольжения ядра через места пропуска входного изображения в соответствии с заранее заданным шагом (но в этом руководстве мы просто предполагаем, что он равен 1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o-E4c803HQM"
      },
      "source": [
        "#######################\n",
        "#  Установите начальные веса и выберите\n",
        "#  количество скрытых слоев\n",
        "#######################\n",
        "weight_scale = .01\n",
        "num_fc = 128\n",
        "num_filter_conv_layer1 = 20\n",
        "num_filter_conv_layer2 = 50\n",
        "\n",
        "W1 = nd.random_normal(shape=(num_filter_conv_layer1, 1, 3,3), scale=weight_scale, ctx=ctx)\n",
        "b1 = nd.random_normal(shape=num_filter_conv_layer1, scale=weight_scale, ctx=ctx)\n",
        "\n",
        "W2 = nd.random_normal(shape=(num_filter_conv_layer2, num_filter_conv_layer1, 5, 5),\n",
        "                                                    scale=weight_scale, ctx=ctx)\n",
        "b2 = nd.random_normal(shape=num_filter_conv_layer2, scale=weight_scale, ctx=ctx)\n",
        "\n",
        "W3 = nd.random_normal(shape=(800, num_fc), scale=weight_scale, ctx=ctx)\n",
        "b3 = nd.random_normal(shape=num_fc, scale=weight_scale, ctx=ctx)\n",
        "\n",
        "W4 = nd.random_normal(shape=(num_fc, num_outputs), scale=weight_scale, ctx=ctx)\n",
        "b4 = nd.random_normal(shape=num_outputs, scale=weight_scale, ctx=ctx)\n",
        "\n",
        "params = [W1, b1, W2, b2, W3, b3, W4, b4]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pmK6D6L5r2v"
      },
      "source": [
        "# Выделите место для градиентов\n",
        "for param in params:\n",
        "    param.attach_grad()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzyRUm2q6Bi1"
      },
      "source": [
        "Чтобы написать CNN с использованием MXNet, мы вызываем функцию *nd.Convolution()*. Эта функция принимает аргументов: входные данные (data), 4-мерную матрицу весов (weight), смещение (bias), форму ядра (kernel) и ряд фильтров (num_filter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79v0PbHW6m7V",
        "outputId": "786e8afd-8c03-4d9a-9a9f-d70ea3b2cb1d"
      },
      "source": [
        "for data, _ in train_data:\n",
        "    data = data.as_in_context(ctx)\n",
        "    break\n",
        "conv = nd.Convolution(data=data, weight=W1, bias=b1, kernel=(3,3), num_filter=num_filter_conv_layer1)\n",
        "print(conv.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 20, 26, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN56ZGdJ69C5"
      },
      "source": [
        "### Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNOHRh796pCR",
        "outputId": "f878dc7b-3c39-4a55-a694-487b3ea067c9"
      },
      "source": [
        "pool = nd.Pooling(data=conv, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
        "print(pool.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 20, 13, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRkAPtLd7BYK"
      },
      "source": [
        "### Функция активации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQVudPpx7ASH"
      },
      "source": [
        "def relu(X):\n",
        "    return nd.maximum(X,nd.zeros_like(X))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE44JuD17c59"
      },
      "source": [
        "### Softmax output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p3e7Xwo7bM_"
      },
      "source": [
        "def softmax(y_linear):\n",
        "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
        "    partition = nd.sum(exp, axis=0, exclude=True).reshape((-1,1))\n",
        "    return exp / partition"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ4PrI2-8J1o"
      },
      "source": [
        "### Softmax cross-entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS_W8jaK8JeB"
      },
      "source": [
        "def softmax_cross_entropy(yhat_linear, y):\n",
        "    return - nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf7NDXem7jRw"
      },
      "source": [
        "### Определяем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7g17HKZ7hW2"
      },
      "source": [
        "def net(X, debug=False):\n",
        "    ########################\n",
        "    #  Define the computation of the first convolutional layer\n",
        "    ########################\n",
        "    h1_conv = nd.Convolution(data=X, weight=W1, bias=b1, kernel=(3,3),\n",
        "                                  num_filter=num_filter_conv_layer1)\n",
        "    h1_activation = relu(h1_conv)\n",
        "    h1 = nd.Pooling(data=h1_activation, pool_type=\"avg\", kernel=(2,2), stride=(2,2))\n",
        "    if debug:\n",
        "        print(\"h1 shape: %s\" % (np.array(h1.shape)))\n",
        "\n",
        "    ########################\n",
        "    #  Define the computation of the second convolutional layer\n",
        "    ########################\n",
        "    h2_conv = nd.Convolution(data=h1, weight=W2, bias=b2, kernel=(5,5),\n",
        "                                  num_filter=num_filter_conv_layer2)\n",
        "    h2_activation = relu(h2_conv)\n",
        "    h2 = nd.Pooling(data=h2_activation, pool_type=\"avg\", kernel=(2,2), stride=(2,2))\n",
        "    if debug:\n",
        "        print(\"h2 shape: %s\" % (np.array(h2.shape)))\n",
        "\n",
        "    ########################\n",
        "    #  Flattening h2 so that we can feed it into a fully-connected layer\n",
        "    ########################\n",
        "    h2 = nd.flatten(h2)\n",
        "    if debug:\n",
        "        print(\"Flat h2 shape: %s\" % (np.array(h2.shape)))\n",
        "\n",
        "    ########################\n",
        "    #  Define the computation of the third (fully-connected) layer\n",
        "    ########################\n",
        "    h3_linear = nd.dot(h2, W3) + b3\n",
        "    h3 = relu(h3_linear)\n",
        "    if debug:\n",
        "        print(\"h3 shape: %s\" % (np.array(h3.shape)))\n",
        "\n",
        "    ########################\n",
        "    #  Define the computation of the output layer\n",
        "    ########################\n",
        "    yhat_linear = nd.dot(h3, W4) + b4\n",
        "    if debug:\n",
        "        print(\"yhat_linear shape: %s\" % (np.array(yhat_linear.shape)))\n",
        "\n",
        "    return yhat_linear"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqOf8W8s7ri0"
      },
      "source": [
        "### Тестовый запуск"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXiBjTAr7pQQ",
        "outputId": "9de51107-c138-481e-9a2e-3ae4c102cb32"
      },
      "source": [
        "output = net(data, debug=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h1 shape: [64 20 13 13]\n",
            "h2 shape: [64 50  4  4]\n",
            "Flat h2 shape: [ 64 800]\n",
            "h3 shape: [ 64 128]\n",
            "yhat_linear shape: [64 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqVtElwH7yWA"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-waGy_I7xBi"
      },
      "source": [
        "def SGD(params, lr):\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzWehsEW74bB"
      },
      "source": [
        "### Evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMNk4eL7wBe"
      },
      "source": [
        "def evaluate_accuracy(data_iterator, net):\n",
        "    numerator = 0.\n",
        "    denominator = 0.\n",
        "    for i, (data, label) in enumerate(data_iterator):\n",
        "        data = data.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        label_one_hot = nd.one_hot(label, 10)\n",
        "        output = net(data)\n",
        "        predictions = nd.argmax(output, axis=1)\n",
        "        numerator += nd.sum(predictions == label)\n",
        "        denominator += data.shape[0]\n",
        "    return (numerator / denominator).asscalar()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRUNrOH87_Ta"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93PKD2O79Ne",
        "outputId": "7a1ce36a-490e-4bc2-cc8a-b2da9e18944b"
      },
      "source": [
        "epochs = 1\n",
        "learning_rate = .01\n",
        "smoothing_constant = .01\n",
        "\n",
        "for e in range(epochs):\n",
        "    for i, (data, label) in enumerate(train_data):\n",
        "        data = data.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        label_one_hot = nd.one_hot(label, num_outputs)\n",
        "        with autograd.record():\n",
        "            output = net(data)\n",
        "            loss = softmax_cross_entropy(output, label_one_hot)\n",
        "        loss.backward()\n",
        "        SGD(params, learning_rate)\n",
        "\n",
        "        ##########################\n",
        "        #  Keep a moving average of the losses\n",
        "        ##########################\n",
        "        curr_loss = nd.mean(loss).asscalar()\n",
        "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
        "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
        "\n",
        "\n",
        "    test_accuracy = evaluate_accuracy(test_data, net)\n",
        "    train_accuracy = evaluate_accuracy(train_data, net)\n",
        "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Loss: 0.19831355076493173, Train_acc 0.95238334, Test_acc 0.9506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aHn9FzY8DkF"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}